{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/larsmagnusson/itf31519-workshop-07-10?scriptVersionId=145074077\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-10-03T07:54:22.333748Z","iopub.execute_input":"2023-10-03T07:54:22.33417Z","iopub.status.idle":"2023-10-03T07:54:22.351479Z","shell.execute_reply.started":"2023-10-03T07:54:22.334138Z","shell.execute_reply":"2023-10-03T07:54:22.3506Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Load dataset\ndataset = pd.read_csv('/kaggle/input/red-wine-quality-cortez-et-al-2009/winequality-red.csv')\n\nfrom sklearn.model_selection import train_test_split\n\n# Split into training and test data (75/25)\ntrain_X, test_X, train_y, test_y = train_test_split(dataset.drop('quality', axis=1), dataset['quality'])\n","metadata":{"execution":{"iopub.status.busy":"2023-10-03T07:54:22.353514Z","iopub.execute_input":"2023-10-03T07:54:22.354431Z","iopub.status.idle":"2023-10-03T07:54:22.377738Z","shell.execute_reply.started":"2023-10-03T07:54:22.35436Z","shell.execute_reply":"2023-10-03T07:54:22.376023Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import GridSearchCV\nfrom sklearn.ensemble import GradientBoostingClassifier\n\n# Create a dictionary with hyperparameter values we want to test\ngb_param = {'learning_rate': [0.025, 0.05, 0.1, 0.15, 0.20], # The \"size\" of each boosting step\n            'n_estimators': [50, 100, 150, 200]} # The number of gradient boosted trees to include in the ensemble\n\n# Create an gridsearch object for finding the best hyperparameter values \n# for a gradient boosting classifier and fit (train) it on the training data\ngb_grid = GridSearchCV(GradientBoostingClassifier(), gb_param)\ngb_grid.fit(train_X, train_y)\n\n# IMPORTANT: gb_grid will in addition to performing the grid search to find the \n# best values also retrain a model using the best found values. This is controlled \n# the refit parameter in GridSearchCV. gb_grid can be used to score and predict using\n# the retrained model.","metadata":{"execution":{"iopub.status.busy":"2023-10-03T07:54:22.416131Z","iopub.execute_input":"2023-10-03T07:54:22.417377Z","iopub.status.idle":"2023-10-03T07:57:47.896422Z","shell.execute_reply.started":"2023-10-03T07:54:22.417337Z","shell.execute_reply":"2023-10-03T07:57:47.895497Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Fetch cross-validation results into a pandas dataframe\ngb_results = pd.DataFrame(gb_grid.cv_results_)\ngb_results","metadata":{"execution":{"iopub.status.busy":"2023-10-03T07:57:47.89834Z","iopub.execute_input":"2023-10-03T07:57:47.89884Z","iopub.status.idle":"2023-10-03T07:57:47.930959Z","shell.execute_reply.started":"2023-10-03T07:57:47.898809Z","shell.execute_reply":"2023-10-03T07:57:47.929831Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# For debug purposes. These values will be our x values in the plot\ngb_results['param_learning_rate']","metadata":{"execution":{"iopub.status.busy":"2023-10-03T07:57:47.932573Z","iopub.execute_input":"2023-10-03T07:57:47.933143Z","iopub.status.idle":"2023-10-03T07:57:47.941519Z","shell.execute_reply.started":"2023-10-03T07:57:47.933108Z","shell.execute_reply":"2023-10-03T07:57:47.940226Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# For debug purposes. These values will be our y values in the plot\ngb_results['mean_test_score']","metadata":{"execution":{"iopub.status.busy":"2023-10-03T07:57:47.943489Z","iopub.execute_input":"2023-10-03T07:57:47.943918Z","iopub.status.idle":"2023-10-03T07:57:47.961006Z","shell.execute_reply.started":"2023-10-03T07:57:47.943877Z","shell.execute_reply":"2023-10-03T07:57:47.959798Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\n# Plot the values directly\nplt.scatter(gb_results['param_n_estimators'], gb_results['mean_test_score'])","metadata":{"execution":{"iopub.status.busy":"2023-10-03T07:57:47.965032Z","iopub.execute_input":"2023-10-03T07:57:47.965408Z","iopub.status.idle":"2023-10-03T07:57:48.20846Z","shell.execute_reply.started":"2023-10-03T07:57:47.96538Z","shell.execute_reply":"2023-10-03T07:57:48.207356Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Find the average score for each value of the learning_rate and n_estimators hyperparameters. We \n# have four results (the number of n_estimator values) for each learning rate. Note that we could \n# potentially select the best score (instead of the mean) for each value as well. \ngb_mean_test_scores = np.array(gb_results['mean_test_score']).reshape(-1,4)\n# The learning rate means are calculated along the columns\ngb_learning_rate_means = np.mean(gb_mean_test_scores, axis=1)\n# The learning rate means are calculated along the rows\ngb_n_estimator_means = np.mean(gb_mean_test_scores, axis=0)\nprint(gb_n_estimator_means)\nprint(gb_learning_rate_means)\n\n# Find the x values directly from the param values. Could be fetched from the \n# cv_results as well\nx_n_estimators = gb_param['n_estimators']\nx_learning_rate = gb_param['learning_rate']\n","metadata":{"execution":{"iopub.status.busy":"2023-10-03T07:57:48.209877Z","iopub.execute_input":"2023-10-03T07:57:48.210328Z","iopub.status.idle":"2023-10-03T07:57:48.220177Z","shell.execute_reply.started":"2023-10-03T07:57:48.210278Z","shell.execute_reply":"2023-10-03T07:57:48.21838Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plot the average performance for each n_estimator and learning_rate value tested\nfig,ax = plt.subplots(1,2,figsize=(10,5))\nax[0].plot(x_learning_rate, gb_learning_rate_means)\nax[1].plot(x_n_estimators, gb_n_estimator_means)","metadata":{"execution":{"iopub.status.busy":"2023-10-03T07:57:48.222029Z","iopub.execute_input":"2023-10-03T07:57:48.222486Z","iopub.status.idle":"2023-10-03T07:57:48.559403Z","shell.execute_reply.started":"2023-10-03T07:57:48.222442Z","shell.execute_reply":"2023-10-03T07:57:48.558243Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\n\n# Create a dictionary with hyperparameter values we want to test\nrf_param = {'max_depth': [4, 6, 8, 10, 12],      # The maximum depth of each decision tree\n            'n_estimators': [50, 100, 150, 200]} # The number of decision trees to include in the ensemble\n\n# Create an gridsearch object for finding the best hyperparameter values \n# for a gradient boosting classifier and fit (train) it on the training data\nrf_grid = GridSearchCV(RandomForestClassifier(), rf_param)\nrf_grid.fit(train_X, train_y)","metadata":{"execution":{"iopub.status.busy":"2023-10-03T07:57:48.560814Z","iopub.execute_input":"2023-10-03T07:57:48.561821Z","iopub.status.idle":"2023-10-03T07:58:20.198601Z","shell.execute_reply.started":"2023-10-03T07:57:48.561784Z","shell.execute_reply":"2023-10-03T07:58:20.197024Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Convert the results from the cross validated grid search into a dataframe \nrf_results = pd.DataFrame(rf_grid.cv_results_)\nrf_results","metadata":{"execution":{"iopub.status.busy":"2023-10-03T07:58:20.199946Z","iopub.execute_input":"2023-10-03T07:58:20.200337Z","iopub.status.idle":"2023-10-03T07:58:20.233344Z","shell.execute_reply.started":"2023-10-03T07:58:20.200305Z","shell.execute_reply":"2023-10-03T07:58:20.231854Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Find the average for each value of the hyperparameter values. We \n# have several results for each learning rate, so we need to combine them. We'll be using the mean,\n# but other methods could illustrate the results more accurately\nrf_mean_test_scores = np.array(rf_results['mean_test_score']).reshape(-1,4)\n\nrf_max_depth_means = np.mean(rf_mean_test_scores, axis=1)\nrf_n_estimators_means = np.mean(rf_mean_test_scores, axis=0)\n\n# We'll use the same x axis points from the gb model since we've tested the same values for n_estimators\nplt.plot(x_n_estimators, gb_n_estimator_means, label=\"GradientBoosting\")\nplt.plot(x_n_estimators, rf_n_estimators_means, label=\"RandomForest\")\nplt.legend()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-10-03T07:58:20.235334Z","iopub.execute_input":"2023-10-03T07:58:20.235755Z","iopub.status.idle":"2023-10-03T07:58:20.45467Z","shell.execute_reply.started":"2023-10-03T07:58:20.235717Z","shell.execute_reply":"2023-10-03T07:58:20.453459Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x_max_depth = rf_param['max_depth']\n# Plot the average performance for each n_estimator and max_depth value tested\nfig,ax = plt.subplots(1,2,figsize=(10,5))\nax[0].plot(x_max_depth, rf_max_depth_means)\nax[1].plot(x_n_estimators, rf_n_estimators_means)","metadata":{"execution":{"iopub.status.busy":"2023-10-03T07:58:20.456224Z","iopub.execute_input":"2023-10-03T07:58:20.456637Z","iopub.status.idle":"2023-10-03T07:58:20.777348Z","shell.execute_reply.started":"2023-10-03T07:58:20.456606Z","shell.execute_reply":"2023-10-03T07:58:20.776511Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import ConfusionMatrixDisplay\n\nfig,ax = plt.subplots(1,2,figsize=(10,5))\nConfusionMatrixDisplay.from_estimator(gb_grid, test_X, test_y, ax=ax[0])\nConfusionMatrixDisplay.from_estimator(rf_grid, test_X, test_y, ax=ax[1])","metadata":{"execution":{"iopub.status.busy":"2023-10-03T07:58:20.778381Z","iopub.execute_input":"2023-10-03T07:58:20.779408Z","iopub.status.idle":"2023-10-03T07:58:21.522376Z","shell.execute_reply.started":"2023-10-03T07:58:20.779375Z","shell.execute_reply":"2023-10-03T07:58:21.521343Z"},"trusted":true},"execution_count":null,"outputs":[]}]}