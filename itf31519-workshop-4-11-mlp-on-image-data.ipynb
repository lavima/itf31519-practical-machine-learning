{"cells":[{"source":"<a href=\"https://www.kaggle.com/code/larsmagnusson/itf31519-workshop-4-11-mlp-on-image-data?scriptVersionId=110027275\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown","outputs":[],"execution_count":0},{"cell_type":"code","execution_count":1,"id":"fe414f88","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2022-11-04T12:15:30.127991Z","iopub.status.busy":"2022-11-04T12:15:30.125909Z","iopub.status.idle":"2022-11-04T12:15:30.141976Z","shell.execute_reply":"2022-11-04T12:15:30.140786Z"},"papermill":{"duration":0.025479,"end_time":"2022-11-04T12:15:30.14483","exception":false,"start_time":"2022-11-04T12:15:30.119351","status":"completed"},"tags":[]},"outputs":[],"source":["# This Python 3 environment comes with many helpful analytics libraries installed\n","# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n","# For example, here's several helpful packages to load\n","\n","import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","\n","# Input data files are available in the read-only \"../input/\" directory\n","# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n","\n","import os\n","for dirname, _, filenames in os.walk('/kaggle/input'):\n","    for filename in filenames:\n","        print(os.path.join(dirname, filename))\n","\n","# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n","# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"]},{"cell_type":"code","execution_count":2,"id":"ebf90b43","metadata":{"execution":{"iopub.execute_input":"2022-11-04T12:15:30.152653Z","iopub.status.busy":"2022-11-04T12:15:30.151868Z","iopub.status.idle":"2022-11-04T12:15:39.15975Z","shell.execute_reply":"2022-11-04T12:15:39.158327Z"},"papermill":{"duration":9.014835,"end_time":"2022-11-04T12:15:39.162635","exception":false,"start_time":"2022-11-04T12:15:30.1478","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n","11493376/11490434 [==============================] - 1s 0us/step\n","11501568/11490434 [==============================] - 1s 0us/step\n"]},{"data":{"text/plain":["array([[[0, 0, 0, ..., 0, 0, 0],\n","        [0, 0, 0, ..., 0, 0, 0],\n","        [0, 0, 0, ..., 0, 0, 0],\n","        ...,\n","        [0, 0, 0, ..., 0, 0, 0],\n","        [0, 0, 0, ..., 0, 0, 0],\n","        [0, 0, 0, ..., 0, 0, 0]],\n","\n","       [[0, 0, 0, ..., 0, 0, 0],\n","        [0, 0, 0, ..., 0, 0, 0],\n","        [0, 0, 0, ..., 0, 0, 0],\n","        ...,\n","        [0, 0, 0, ..., 0, 0, 0],\n","        [0, 0, 0, ..., 0, 0, 0],\n","        [0, 0, 0, ..., 0, 0, 0]],\n","\n","       [[0, 0, 0, ..., 0, 0, 0],\n","        [0, 0, 0, ..., 0, 0, 0],\n","        [0, 0, 0, ..., 0, 0, 0],\n","        ...,\n","        [0, 0, 0, ..., 0, 0, 0],\n","        [0, 0, 0, ..., 0, 0, 0],\n","        [0, 0, 0, ..., 0, 0, 0]],\n","\n","       ...,\n","\n","       [[0, 0, 0, ..., 0, 0, 0],\n","        [0, 0, 0, ..., 0, 0, 0],\n","        [0, 0, 0, ..., 0, 0, 0],\n","        ...,\n","        [0, 0, 0, ..., 0, 0, 0],\n","        [0, 0, 0, ..., 0, 0, 0],\n","        [0, 0, 0, ..., 0, 0, 0]],\n","\n","       [[0, 0, 0, ..., 0, 0, 0],\n","        [0, 0, 0, ..., 0, 0, 0],\n","        [0, 0, 0, ..., 0, 0, 0],\n","        ...,\n","        [0, 0, 0, ..., 0, 0, 0],\n","        [0, 0, 0, ..., 0, 0, 0],\n","        [0, 0, 0, ..., 0, 0, 0]],\n","\n","       [[0, 0, 0, ..., 0, 0, 0],\n","        [0, 0, 0, ..., 0, 0, 0],\n","        [0, 0, 0, ..., 0, 0, 0],\n","        ...,\n","        [0, 0, 0, ..., 0, 0, 0],\n","        [0, 0, 0, ..., 0, 0, 0],\n","        [0, 0, 0, ..., 0, 0, 0]]], dtype=uint8)"]},"execution_count":2,"metadata":{},"output_type":"execute_result"}],"source":["# Load MNIST dataset directly from tensorflow\n","from tensorflow.keras.datasets.mnist import load_data\n","# Data is returned already split into train and test data, and inputs and outputs\n","(train_x, train_y), (test_x, test_y) = load_data()\n","# Show the contents of the training inputs\n","train_x"]},{"cell_type":"code","execution_count":3,"id":"1616db99","metadata":{"execution":{"iopub.execute_input":"2022-11-04T12:15:39.173953Z","iopub.status.busy":"2022-11-04T12:15:39.173026Z","iopub.status.idle":"2022-11-04T12:15:39.417934Z","shell.execute_reply":"2022-11-04T12:15:39.416581Z"},"papermill":{"duration":0.253369,"end_time":"2022-11-04T12:15:39.420655","exception":false,"start_time":"2022-11-04T12:15:39.167286","status":"completed"},"tags":[]},"outputs":[{"data":{"text/plain":["array([[[0.        , 0.        , 0.        , 0.        , 0.        ,\n","         0.        , 0.        , 0.        , 0.        , 0.        ,\n","         0.        , 0.        , 0.        , 0.        , 0.        ,\n","         0.        , 0.        , 0.        , 0.        , 0.        ,\n","         0.        , 0.        , 0.        , 0.        , 0.        ,\n","         0.        , 0.        , 0.        ],\n","        [0.        , 0.        , 0.        , 0.        , 0.        ,\n","         0.        , 0.        , 0.        , 0.        , 0.        ,\n","         0.        , 0.        , 0.        , 0.        , 0.        ,\n","         0.        , 0.        , 0.        , 0.        , 0.        ,\n","         0.        , 0.        , 0.        , 0.        , 0.        ,\n","         0.        , 0.        , 0.        ],\n","        [0.        , 0.        , 0.        , 0.        , 0.        ,\n","         0.        , 0.        , 0.        , 0.        , 0.        ,\n","         0.        , 0.        , 0.        , 0.        , 0.        ,\n","         0.        , 0.        , 0.        , 0.        , 0.        ,\n","         0.        , 0.        , 0.        , 0.        , 0.        ,\n","         0.        , 0.        , 0.        ],\n","        [0.        , 0.        , 0.        , 0.        , 0.        ,\n","         0.        , 0.        , 0.        , 0.        , 0.        ,\n","         0.        , 0.        , 0.        , 0.        , 0.        ,\n","         0.        , 0.        , 0.        , 0.        , 0.        ,\n","         0.        , 0.        , 0.        , 0.        , 0.        ,\n","         0.        , 0.        , 0.        ],\n","        [0.        , 0.        , 0.        , 0.        , 0.        ,\n","         0.        , 0.        , 0.        , 0.        , 0.        ,\n","         0.        , 0.        , 0.        , 0.        , 0.        ,\n","         0.        , 0.        , 0.        , 0.        , 0.        ,\n","         0.        , 0.        , 0.        , 0.        , 0.        ,\n","         0.        , 0.        , 0.        ],\n","        [0.        , 0.        , 0.        , 0.        , 0.        ,\n","         0.        , 0.        , 0.        , 0.        , 0.        ,\n","         0.        , 0.        , 0.01176471, 0.07058824, 0.07058824,\n","         0.07058824, 0.49411765, 0.53333333, 0.68627451, 0.10196078,\n","         0.65098039, 1.        , 0.96862745, 0.49803922, 0.        ,\n","         0.        , 0.        , 0.        ],\n","        [0.        , 0.        , 0.        , 0.        , 0.        ,\n","         0.        , 0.        , 0.        , 0.11764706, 0.14117647,\n","         0.36862745, 0.60392157, 0.66666667, 0.99215686, 0.99215686,\n","         0.99215686, 0.99215686, 0.99215686, 0.88235294, 0.6745098 ,\n","         0.99215686, 0.94901961, 0.76470588, 0.25098039, 0.        ,\n","         0.        , 0.        , 0.        ],\n","        [0.        , 0.        , 0.        , 0.        , 0.        ,\n","         0.        , 0.        , 0.19215686, 0.93333333, 0.99215686,\n","         0.99215686, 0.99215686, 0.99215686, 0.99215686, 0.99215686,\n","         0.99215686, 0.99215686, 0.98431373, 0.36470588, 0.32156863,\n","         0.32156863, 0.21960784, 0.15294118, 0.        , 0.        ,\n","         0.        , 0.        , 0.        ],\n","        [0.        , 0.        , 0.        , 0.        , 0.        ,\n","         0.        , 0.        , 0.07058824, 0.85882353, 0.99215686,\n","         0.99215686, 0.99215686, 0.99215686, 0.99215686, 0.77647059,\n","         0.71372549, 0.96862745, 0.94509804, 0.        , 0.        ,\n","         0.        , 0.        , 0.        , 0.        , 0.        ,\n","         0.        , 0.        , 0.        ],\n","        [0.        , 0.        , 0.        , 0.        , 0.        ,\n","         0.        , 0.        , 0.        , 0.31372549, 0.61176471,\n","         0.41960784, 0.99215686, 0.99215686, 0.80392157, 0.04313725,\n","         0.        , 0.16862745, 0.60392157, 0.        , 0.        ,\n","         0.        , 0.        , 0.        , 0.        , 0.        ,\n","         0.        , 0.        , 0.        ],\n","        [0.        , 0.        , 0.        , 0.        , 0.        ,\n","         0.        , 0.        , 0.        , 0.        , 0.05490196,\n","         0.00392157, 0.60392157, 0.99215686, 0.35294118, 0.        ,\n","         0.        , 0.        , 0.        , 0.        , 0.        ,\n","         0.        , 0.        , 0.        , 0.        , 0.        ,\n","         0.        , 0.        , 0.        ],\n","        [0.        , 0.        , 0.        , 0.        , 0.        ,\n","         0.        , 0.        , 0.        , 0.        , 0.        ,\n","         0.        , 0.54509804, 0.99215686, 0.74509804, 0.00784314,\n","         0.        , 0.        , 0.        , 0.        , 0.        ,\n","         0.        , 0.        , 0.        , 0.        , 0.        ,\n","         0.        , 0.        , 0.        ],\n","        [0.        , 0.        , 0.        , 0.        , 0.        ,\n","         0.        , 0.        , 0.        , 0.        , 0.        ,\n","         0.        , 0.04313725, 0.74509804, 0.99215686, 0.2745098 ,\n","         0.        , 0.        , 0.        , 0.        , 0.        ,\n","         0.        , 0.        , 0.        , 0.        , 0.        ,\n","         0.        , 0.        , 0.        ],\n","        [0.        , 0.        , 0.        , 0.        , 0.        ,\n","         0.        , 0.        , 0.        , 0.        , 0.        ,\n","         0.        , 0.        , 0.1372549 , 0.94509804, 0.88235294,\n","         0.62745098, 0.42352941, 0.00392157, 0.        , 0.        ,\n","         0.        , 0.        , 0.        , 0.        , 0.        ,\n","         0.        , 0.        , 0.        ],\n","        [0.        , 0.        , 0.        , 0.        , 0.        ,\n","         0.        , 0.        , 0.        , 0.        , 0.        ,\n","         0.        , 0.        , 0.        , 0.31764706, 0.94117647,\n","         0.99215686, 0.99215686, 0.46666667, 0.09803922, 0.        ,\n","         0.        , 0.        , 0.        , 0.        , 0.        ,\n","         0.        , 0.        , 0.        ],\n","        [0.        , 0.        , 0.        , 0.        , 0.        ,\n","         0.        , 0.        , 0.        , 0.        , 0.        ,\n","         0.        , 0.        , 0.        , 0.        , 0.17647059,\n","         0.72941176, 0.99215686, 0.99215686, 0.58823529, 0.10588235,\n","         0.        , 0.        , 0.        , 0.        , 0.        ,\n","         0.        , 0.        , 0.        ],\n","        [0.        , 0.        , 0.        , 0.        , 0.        ,\n","         0.        , 0.        , 0.        , 0.        , 0.        ,\n","         0.        , 0.        , 0.        , 0.        , 0.        ,\n","         0.0627451 , 0.36470588, 0.98823529, 0.99215686, 0.73333333,\n","         0.        , 0.        , 0.        , 0.        , 0.        ,\n","         0.        , 0.        , 0.        ],\n","        [0.        , 0.        , 0.        , 0.        , 0.        ,\n","         0.        , 0.        , 0.        , 0.        , 0.        ,\n","         0.        , 0.        , 0.        , 0.        , 0.        ,\n","         0.        , 0.        , 0.97647059, 0.99215686, 0.97647059,\n","         0.25098039, 0.        , 0.        , 0.        , 0.        ,\n","         0.        , 0.        , 0.        ],\n","        [0.        , 0.        , 0.        , 0.        , 0.        ,\n","         0.        , 0.        , 0.        , 0.        , 0.        ,\n","         0.        , 0.        , 0.        , 0.        , 0.18039216,\n","         0.50980392, 0.71764706, 0.99215686, 0.99215686, 0.81176471,\n","         0.00784314, 0.        , 0.        , 0.        , 0.        ,\n","         0.        , 0.        , 0.        ],\n","        [0.        , 0.        , 0.        , 0.        , 0.        ,\n","         0.        , 0.        , 0.        , 0.        , 0.        ,\n","         0.        , 0.        , 0.15294118, 0.58039216, 0.89803922,\n","         0.99215686, 0.99215686, 0.99215686, 0.98039216, 0.71372549,\n","         0.        , 0.        , 0.        , 0.        , 0.        ,\n","         0.        , 0.        , 0.        ],\n","        [0.        , 0.        , 0.        , 0.        , 0.        ,\n","         0.        , 0.        , 0.        , 0.        , 0.        ,\n","         0.09411765, 0.44705882, 0.86666667, 0.99215686, 0.99215686,\n","         0.99215686, 0.99215686, 0.78823529, 0.30588235, 0.        ,\n","         0.        , 0.        , 0.        , 0.        , 0.        ,\n","         0.        , 0.        , 0.        ],\n","        [0.        , 0.        , 0.        , 0.        , 0.        ,\n","         0.        , 0.        , 0.        , 0.09019608, 0.25882353,\n","         0.83529412, 0.99215686, 0.99215686, 0.99215686, 0.99215686,\n","         0.77647059, 0.31764706, 0.00784314, 0.        , 0.        ,\n","         0.        , 0.        , 0.        , 0.        , 0.        ,\n","         0.        , 0.        , 0.        ],\n","        [0.        , 0.        , 0.        , 0.        , 0.        ,\n","         0.        , 0.07058824, 0.67058824, 0.85882353, 0.99215686,\n","         0.99215686, 0.99215686, 0.99215686, 0.76470588, 0.31372549,\n","         0.03529412, 0.        , 0.        , 0.        , 0.        ,\n","         0.        , 0.        , 0.        , 0.        , 0.        ,\n","         0.        , 0.        , 0.        ],\n","        [0.        , 0.        , 0.        , 0.        , 0.21568627,\n","         0.6745098 , 0.88627451, 0.99215686, 0.99215686, 0.99215686,\n","         0.99215686, 0.95686275, 0.52156863, 0.04313725, 0.        ,\n","         0.        , 0.        , 0.        , 0.        , 0.        ,\n","         0.        , 0.        , 0.        , 0.        , 0.        ,\n","         0.        , 0.        , 0.        ],\n","        [0.        , 0.        , 0.        , 0.        , 0.53333333,\n","         0.99215686, 0.99215686, 0.99215686, 0.83137255, 0.52941176,\n","         0.51764706, 0.0627451 , 0.        , 0.        , 0.        ,\n","         0.        , 0.        , 0.        , 0.        , 0.        ,\n","         0.        , 0.        , 0.        , 0.        , 0.        ,\n","         0.        , 0.        , 0.        ],\n","        [0.        , 0.        , 0.        , 0.        , 0.        ,\n","         0.        , 0.        , 0.        , 0.        , 0.        ,\n","         0.        , 0.        , 0.        , 0.        , 0.        ,\n","         0.        , 0.        , 0.        , 0.        , 0.        ,\n","         0.        , 0.        , 0.        , 0.        , 0.        ,\n","         0.        , 0.        , 0.        ],\n","        [0.        , 0.        , 0.        , 0.        , 0.        ,\n","         0.        , 0.        , 0.        , 0.        , 0.        ,\n","         0.        , 0.        , 0.        , 0.        , 0.        ,\n","         0.        , 0.        , 0.        , 0.        , 0.        ,\n","         0.        , 0.        , 0.        , 0.        , 0.        ,\n","         0.        , 0.        , 0.        ],\n","        [0.        , 0.        , 0.        , 0.        , 0.        ,\n","         0.        , 0.        , 0.        , 0.        , 0.        ,\n","         0.        , 0.        , 0.        , 0.        , 0.        ,\n","         0.        , 0.        , 0.        , 0.        , 0.        ,\n","         0.        , 0.        , 0.        , 0.        , 0.        ,\n","         0.        , 0.        , 0.        ]]])"]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["# Normalize the input values \n","train_x = train_x / 255.0\n","test_x = test_x / 255.0\n","\n","import matplotlib.pyplot as plt\n","\n","# Show the normalized trainining inputs\n","train_x[:1]"]},{"cell_type":"code","execution_count":4,"id":"b3554690","metadata":{"execution":{"iopub.execute_input":"2022-11-04T12:15:39.432423Z","iopub.status.busy":"2022-11-04T12:15:39.431568Z","iopub.status.idle":"2022-11-04T12:16:01.186121Z","shell.execute_reply":"2022-11-04T12:16:01.184693Z"},"papermill":{"duration":21.763395,"end_time":"2022-11-04T12:16:01.188845","exception":false,"start_time":"2022-11-04T12:15:39.42545","status":"completed"},"tags":[]},"outputs":[{"name":"stderr","output_type":"stream","text":["2022-11-04 12:15:39.476984: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n","2022-11-04 12:15:40.157653: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 1/5\n","1875/1875 [==============================] - 5s 2ms/step - loss: 0.4313 - accuracy: 0.8843\n","Epoch 2/5\n","1875/1875 [==============================] - 4s 2ms/step - loss: 0.2186 - accuracy: 0.9368\n","Epoch 3/5\n","1875/1875 [==============================] - 4s 2ms/step - loss: 0.1652 - accuracy: 0.9513\n","Epoch 4/5\n","1875/1875 [==============================] - 4s 2ms/step - loss: 0.1312 - accuracy: 0.9622\n","Epoch 5/5\n","1875/1875 [==============================] - 4s 2ms/step - loss: 0.1099 - accuracy: 0.9674\n"]},{"data":{"text/plain":["<keras.callbacks.History at 0x7f4418ccd750>"]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense, Flatten, Dropout\n","from tensorflow.keras.losses import SparseCategoricalCrossentropy\n","\n","# Create our model. A sequential model is a sequence of layers. \n","model = Sequential()\n","# Flatten the input tensors\n","model.add(Flatten(input_shape=(28,28)))\n","# Fully-connected layer with 120 neurons\n","model.add(Dense(120, activation='sigmoid'))\n","# Dropout layer with 0.1 drop out ratio i.e. 10% of the inputs will randomly be set to 0\n","# Can reduce overfitting (increase regularization)\n","model.add(Dropout(0.1))\n","# Output layer with one neuron per class\n","model.add(Dense(10))\n","\n","# Finish our model by specifying optimizer, loss function and metrics \n","model.compile(optimizer='adam', loss=SparseCategoricalCrossentropy(from_logits=True), metrics=['accuracy'])\n","\n","# Train our network using 32 images between each weight update and run through all the data 5 times\n","model.fit(train_x, train_y, epochs=5, batch_size=32)"]},{"cell_type":"code","execution_count":5,"id":"8e770d78","metadata":{"execution":{"iopub.execute_input":"2022-11-04T12:16:01.252576Z","iopub.status.busy":"2022-11-04T12:16:01.252152Z","iopub.status.idle":"2022-11-04T12:16:01.975914Z","shell.execute_reply":"2022-11-04T12:16:01.97452Z"},"papermill":{"duration":0.759336,"end_time":"2022-11-04T12:16:01.97853","exception":false,"start_time":"2022-11-04T12:16:01.219194","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["313/313 [==============================] - 1s 1ms/step - loss: 0.1019 - accuracy: 0.9702\n"]},{"data":{"text/plain":["[0.10189338773488998, 0.9702000021934509]"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["# Evaluate the performance on test data\n","model.evaluate(test_x, test_y)"]},{"cell_type":"code","execution_count":6,"id":"b7b0db3f","metadata":{"execution":{"iopub.execute_input":"2022-11-04T12:16:02.045012Z","iopub.status.busy":"2022-11-04T12:16:02.044447Z","iopub.status.idle":"2022-11-04T12:21:21.933106Z","shell.execute_reply":"2022-11-04T12:21:21.931569Z"},"papermill":{"duration":319.9259,"end_time":"2022-11-04T12:21:21.935984","exception":false,"start_time":"2022-11-04T12:16:02.010084","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/5\n","1500/1500 [==============================] - 4s 2ms/step - loss: 0.3084 - accuracy: 0.9115\n","Epoch 2/5\n","1500/1500 [==============================] - 4s 3ms/step - loss: 0.1436 - accuracy: 0.9575\n","Epoch 3/5\n","1500/1500 [==============================] - 3s 2ms/step - loss: 0.1015 - accuracy: 0.9700\n","Epoch 4/5\n","1500/1500 [==============================] - 3s 2ms/step - loss: 0.0797 - accuracy: 0.9755\n","Epoch 5/5\n","1500/1500 [==============================] - 3s 2ms/step - loss: 0.0650 - accuracy: 0.9798\n","375/375 [==============================] - 1s 1ms/step - loss: 0.0849 - accuracy: 0.9754\n","Epoch 1/5\n","1500/1500 [==============================] - 4s 2ms/step - loss: 0.2972 - accuracy: 0.9148\n","Epoch 2/5\n","1500/1500 [==============================] - 3s 2ms/step - loss: 0.1366 - accuracy: 0.9587\n","Epoch 3/5\n","1500/1500 [==============================] - 3s 2ms/step - loss: 0.1001 - accuracy: 0.9699\n","Epoch 4/5\n","1500/1500 [==============================] - 3s 2ms/step - loss: 0.0790 - accuracy: 0.9761\n","Epoch 5/5\n","1500/1500 [==============================] - 3s 2ms/step - loss: 0.0656 - accuracy: 0.9796\n","375/375 [==============================] - 1s 1ms/step - loss: 0.0852 - accuracy: 0.9753\n","Epoch 1/5\n","1500/1500 [==============================] - 4s 2ms/step - loss: 0.3048 - accuracy: 0.9111\n","Epoch 2/5\n","1500/1500 [==============================] - 3s 2ms/step - loss: 0.1439 - accuracy: 0.9579\n","Epoch 3/5\n","1500/1500 [==============================] - 4s 2ms/step - loss: 0.1015 - accuracy: 0.9696\n","Epoch 4/5\n","1500/1500 [==============================] - 3s 2ms/step - loss: 0.0772 - accuracy: 0.9763\n","Epoch 5/5\n","1500/1500 [==============================] - 4s 2ms/step - loss: 0.0628 - accuracy: 0.9801\n","375/375 [==============================] - 1s 1ms/step - loss: 0.0895 - accuracy: 0.9733\n","Epoch 1/5\n","1500/1500 [==============================] - 4s 2ms/step - loss: 0.3014 - accuracy: 0.9136\n","Epoch 2/5\n","1500/1500 [==============================] - 4s 2ms/step - loss: 0.1416 - accuracy: 0.9578\n","Epoch 3/5\n","1500/1500 [==============================] - 3s 2ms/step - loss: 0.1022 - accuracy: 0.9689\n","Epoch 4/5\n","1500/1500 [==============================] - 4s 3ms/step - loss: 0.0799 - accuracy: 0.9760\n","Epoch 5/5\n","1500/1500 [==============================] - 3s 2ms/step - loss: 0.0634 - accuracy: 0.9797\n","375/375 [==============================] - 1s 1ms/step - loss: 0.1112 - accuracy: 0.9685\n","Epoch 1/5\n","1500/1500 [==============================] - 4s 2ms/step - loss: 0.2994 - accuracy: 0.9146\n","Epoch 2/5\n","1500/1500 [==============================] - 3s 2ms/step - loss: 0.1406 - accuracy: 0.9588\n","Epoch 3/5\n","1500/1500 [==============================] - 3s 2ms/step - loss: 0.1017 - accuracy: 0.9691\n","Epoch 4/5\n","1500/1500 [==============================] - 3s 2ms/step - loss: 0.0781 - accuracy: 0.9768\n","Epoch 5/5\n","1500/1500 [==============================] - 3s 2ms/step - loss: 0.0639 - accuracy: 0.9798\n","375/375 [==============================] - 1s 1ms/step - loss: 0.0841 - accuracy: 0.9744\n","Epoch 1/5\n","1500/1500 [==============================] - 4s 2ms/step - loss: 0.3229 - accuracy: 0.9064\n","Epoch 2/5\n","1500/1500 [==============================] - 4s 3ms/step - loss: 0.1525 - accuracy: 0.9549\n","Epoch 3/5\n","1500/1500 [==============================] - 4s 3ms/step - loss: 0.1116 - accuracy: 0.9659\n","Epoch 4/5\n","1500/1500 [==============================] - 4s 2ms/step - loss: 0.0901 - accuracy: 0.9724\n","Epoch 5/5\n","1500/1500 [==============================] - 4s 2ms/step - loss: 0.0764 - accuracy: 0.9756\n","375/375 [==============================] - 1s 2ms/step - loss: 0.0811 - accuracy: 0.9743\n","Epoch 1/5\n","1500/1500 [==============================] - 5s 3ms/step - loss: 0.3145 - accuracy: 0.9086\n","Epoch 2/5\n","1500/1500 [==============================] - 4s 3ms/step - loss: 0.1506 - accuracy: 0.9560\n","Epoch 3/5\n","1500/1500 [==============================] - 4s 3ms/step - loss: 0.1130 - accuracy: 0.9658\n","Epoch 4/5\n","1500/1500 [==============================] - 3s 2ms/step - loss: 0.0938 - accuracy: 0.9709\n","Epoch 5/5\n","1500/1500 [==============================] - 5s 3ms/step - loss: 0.0783 - accuracy: 0.9760\n","375/375 [==============================] - 1s 2ms/step - loss: 0.0897 - accuracy: 0.9732\n","Epoch 1/5\n","1500/1500 [==============================] - 4s 3ms/step - loss: 0.3192 - accuracy: 0.9069\n","Epoch 2/5\n","1500/1500 [==============================] - 4s 3ms/step - loss: 0.1552 - accuracy: 0.9539\n","Epoch 3/5\n","1500/1500 [==============================] - 4s 3ms/step - loss: 0.1176 - accuracy: 0.9651\n","Epoch 4/5\n","1500/1500 [==============================] - 4s 3ms/step - loss: 0.0919 - accuracy: 0.9712\n","Epoch 5/5\n","1500/1500 [==============================] - 4s 3ms/step - loss: 0.0799 - accuracy: 0.9751\n","375/375 [==============================] - 1s 2ms/step - loss: 0.0982 - accuracy: 0.9718\n","Epoch 1/5\n","1500/1500 [==============================] - 4s 3ms/step - loss: 0.3242 - accuracy: 0.9062\n","Epoch 2/5\n","1500/1500 [==============================] - 4s 3ms/step - loss: 0.1588 - accuracy: 0.9531\n","Epoch 3/5\n","1500/1500 [==============================] - 4s 3ms/step - loss: 0.1175 - accuracy: 0.9647\n","Epoch 4/5\n","1500/1500 [==============================] - 4s 3ms/step - loss: 0.0942 - accuracy: 0.9709\n","Epoch 5/5\n","1500/1500 [==============================] - 4s 2ms/step - loss: 0.0781 - accuracy: 0.9747\n","375/375 [==============================] - 1s 2ms/step - loss: 0.1024 - accuracy: 0.9705\n","Epoch 1/5\n","1500/1500 [==============================] - 4s 2ms/step - loss: 0.3266 - accuracy: 0.9052\n","Epoch 2/5\n","1500/1500 [==============================] - 4s 2ms/step - loss: 0.1571 - accuracy: 0.9535\n","Epoch 3/5\n","1500/1500 [==============================] - 4s 2ms/step - loss: 0.1187 - accuracy: 0.9646\n","Epoch 4/5\n","1500/1500 [==============================] - 3s 2ms/step - loss: 0.0958 - accuracy: 0.9703\n","Epoch 5/5\n","1500/1500 [==============================] - 4s 3ms/step - loss: 0.0787 - accuracy: 0.9760\n","375/375 [==============================] - 1s 2ms/step - loss: 0.0877 - accuracy: 0.9745\n","Epoch 1/5\n","1500/1500 [==============================] - 4s 2ms/step - loss: 0.3528 - accuracy: 0.8965\n","Epoch 2/5\n","1500/1500 [==============================] - 4s 2ms/step - loss: 0.1808 - accuracy: 0.9458\n","Epoch 3/5\n","1500/1500 [==============================] - 4s 2ms/step - loss: 0.1403 - accuracy: 0.9576\n","Epoch 4/5\n","1500/1500 [==============================] - 3s 2ms/step - loss: 0.1162 - accuracy: 0.9642\n","Epoch 5/5\n","1500/1500 [==============================] - 3s 2ms/step - loss: 0.1025 - accuracy: 0.9684\n","375/375 [==============================] - 1s 1ms/step - loss: 0.0898 - accuracy: 0.9722\n","Epoch 1/5\n","1500/1500 [==============================] - 4s 2ms/step - loss: 0.3452 - accuracy: 0.8990\n","Epoch 2/5\n","1500/1500 [==============================] - 3s 2ms/step - loss: 0.1740 - accuracy: 0.9484\n","Epoch 3/5\n","1500/1500 [==============================] - 4s 3ms/step - loss: 0.1340 - accuracy: 0.9587\n","Epoch 4/5\n","1500/1500 [==============================] - 4s 2ms/step - loss: 0.1131 - accuracy: 0.9662\n","Epoch 5/5\n","1500/1500 [==============================] - 3s 2ms/step - loss: 0.0976 - accuracy: 0.9696\n","375/375 [==============================] - 1s 2ms/step - loss: 0.1034 - accuracy: 0.9705\n","Epoch 1/5\n","1500/1500 [==============================] - 4s 2ms/step - loss: 0.3501 - accuracy: 0.8992\n","Epoch 2/5\n","1500/1500 [==============================] - 4s 2ms/step - loss: 0.1767 - accuracy: 0.9485\n","Epoch 3/5\n","1500/1500 [==============================] - 4s 2ms/step - loss: 0.1367 - accuracy: 0.9591\n","Epoch 4/5\n","1500/1500 [==============================] - 4s 2ms/step - loss: 0.1139 - accuracy: 0.9661\n","Epoch 5/5\n","1500/1500 [==============================] - 4s 2ms/step - loss: 0.1016 - accuracy: 0.9687\n","375/375 [==============================] - 1s 2ms/step - loss: 0.0992 - accuracy: 0.9708\n","Epoch 1/5\n","1500/1500 [==============================] - 4s 3ms/step - loss: 0.3366 - accuracy: 0.9019\n","Epoch 2/5\n","1500/1500 [==============================] - 4s 2ms/step - loss: 0.1718 - accuracy: 0.9494\n","Epoch 3/5\n","1500/1500 [==============================] - 3s 2ms/step - loss: 0.1298 - accuracy: 0.9610\n","Epoch 4/5\n","1500/1500 [==============================] - 4s 2ms/step - loss: 0.1099 - accuracy: 0.9667\n","Epoch 5/5\n","1500/1500 [==============================] - 3s 2ms/step - loss: 0.0937 - accuracy: 0.9706\n","375/375 [==============================] - 1s 2ms/step - loss: 0.1036 - accuracy: 0.9686\n","Epoch 1/5\n","1500/1500 [==============================] - 4s 2ms/step - loss: 0.3545 - accuracy: 0.8979\n","Epoch 2/5\n","1500/1500 [==============================] - 3s 2ms/step - loss: 0.1789 - accuracy: 0.9470\n","Epoch 3/5\n","1500/1500 [==============================] - 4s 2ms/step - loss: 0.1382 - accuracy: 0.9583\n","Epoch 4/5\n","1500/1500 [==============================] - 4s 3ms/step - loss: 0.1145 - accuracy: 0.9645\n","Epoch 5/5\n","1500/1500 [==============================] - 4s 3ms/step - loss: 0.1006 - accuracy: 0.9694\n","375/375 [==============================] - 1s 2ms/step - loss: 0.0908 - accuracy: 0.9730\n","Epoch 1/5\n","1875/1875 [==============================] - 5s 2ms/step - loss: 0.2680 - accuracy: 0.9235\n","Epoch 2/5\n","1875/1875 [==============================] - 4s 2ms/step - loss: 0.1271 - accuracy: 0.9614\n","Epoch 3/5\n","1875/1875 [==============================] - 4s 2ms/step - loss: 0.0914 - accuracy: 0.9719\n","Epoch 4/5\n","1875/1875 [==============================] - 4s 2ms/step - loss: 0.0733 - accuracy: 0.9771\n","Epoch 5/5\n","1875/1875 [==============================] - 4s 2ms/step - loss: 0.0604 - accuracy: 0.9808\n"]},{"data":{"text/plain":["GridSearchCV(estimator=<keras.wrappers.scikit_learn.KerasClassifier object at 0x7f4418c50490>,\n","             param_grid={'drop_out': [0.1, 0.2, 0.3]})"]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["from sklearn.model_selection import GridSearchCV\n","from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n","\n","# A function for creating our model. The arguments are parameters the we want to be controllable\n","def create_model(drop_out):\n","    # The same architecture as before, but now the drop_out is controllable by the search\n","    model = Sequential([\n","          Flatten(input_shape=(28, 28)),\n","          Dense(128, activation='relu'),\n","          Dropout(drop_out),\n","          Dense(10)\n","    ])\n","    # Finish the model by specifying optimizer, loss, and metric\n","    model.compile(optimizer='adam', loss=SparseCategoricalCrossentropy(from_logits=True), metrics=['accuracy'])\n","    return model\n","\n","# Create our classifier that points to the function above\n","classifier = KerasClassifier(create_model, epochs=5, batch_size=32)\n","\n","# Set up grid search like normal\n","params = {'drop_out':[0.1, 0.2, 0.3]}\n","grid = GridSearchCV(classifier, params)\n","grid.fit(train_x, train_y)"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.12"},"papermill":{"default_parameters":{},"duration":364.396001,"end_time":"2022-11-04T12:21:25.156855","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2022-11-04T12:15:20.760854","version":"2.3.4"}},"nbformat":4,"nbformat_minor":5}