{"cells":[{"source":"<a href=\"https://www.kaggle.com/code/larsmagnusson/itf31519-workshop-3-11-ff-on-image-data?scriptVersionId=149080240\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","execution_count":1,"id":"c16b16de","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2023-11-02T21:23:37.02718Z","iopub.status.busy":"2023-11-02T21:23:37.026439Z","iopub.status.idle":"2023-11-02T21:23:37.036356Z","shell.execute_reply":"2023-11-02T21:23:37.035568Z"},"papermill":{"duration":0.017258,"end_time":"2023-11-02T21:23:37.038736","exception":false,"start_time":"2023-11-02T21:23:37.021478","status":"completed"},"tags":[]},"outputs":[],"source":["# This Python 3 environment comes with many helpful analytics libraries installed\n","# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n","# For example, here's several helpful packages to load\n","\n","import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","\n","# Input data files are available in the read-only \"../input/\" directory\n","# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n","\n","import os\n","for dirname, _, filenames in os.walk('/kaggle/input'):\n","    for filename in filenames:\n","        print(os.path.join(dirname, filename))\n","\n","# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n","# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"]},{"cell_type":"code","execution_count":2,"id":"2ec82d19","metadata":{"execution":{"iopub.execute_input":"2023-11-02T21:23:37.045187Z","iopub.status.busy":"2023-11-02T21:23:37.044858Z","iopub.status.idle":"2023-11-02T21:23:43.421225Z","shell.execute_reply":"2023-11-02T21:23:43.420081Z"},"papermill":{"duration":6.381851,"end_time":"2023-11-02T21:23:43.423296","exception":false,"start_time":"2023-11-02T21:23:37.041445","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n","11493376/11490434 [==============================] - 0s 0us/step\n","11501568/11490434 [==============================] - 0s 0us/step\n"]},{"data":{"text/plain":["array([[[0, 0, 0, ..., 0, 0, 0],\n","        [0, 0, 0, ..., 0, 0, 0],\n","        [0, 0, 0, ..., 0, 0, 0],\n","        ...,\n","        [0, 0, 0, ..., 0, 0, 0],\n","        [0, 0, 0, ..., 0, 0, 0],\n","        [0, 0, 0, ..., 0, 0, 0]],\n","\n","       [[0, 0, 0, ..., 0, 0, 0],\n","        [0, 0, 0, ..., 0, 0, 0],\n","        [0, 0, 0, ..., 0, 0, 0],\n","        ...,\n","        [0, 0, 0, ..., 0, 0, 0],\n","        [0, 0, 0, ..., 0, 0, 0],\n","        [0, 0, 0, ..., 0, 0, 0]],\n","\n","       [[0, 0, 0, ..., 0, 0, 0],\n","        [0, 0, 0, ..., 0, 0, 0],\n","        [0, 0, 0, ..., 0, 0, 0],\n","        ...,\n","        [0, 0, 0, ..., 0, 0, 0],\n","        [0, 0, 0, ..., 0, 0, 0],\n","        [0, 0, 0, ..., 0, 0, 0]],\n","\n","       ...,\n","\n","       [[0, 0, 0, ..., 0, 0, 0],\n","        [0, 0, 0, ..., 0, 0, 0],\n","        [0, 0, 0, ..., 0, 0, 0],\n","        ...,\n","        [0, 0, 0, ..., 0, 0, 0],\n","        [0, 0, 0, ..., 0, 0, 0],\n","        [0, 0, 0, ..., 0, 0, 0]],\n","\n","       [[0, 0, 0, ..., 0, 0, 0],\n","        [0, 0, 0, ..., 0, 0, 0],\n","        [0, 0, 0, ..., 0, 0, 0],\n","        ...,\n","        [0, 0, 0, ..., 0, 0, 0],\n","        [0, 0, 0, ..., 0, 0, 0],\n","        [0, 0, 0, ..., 0, 0, 0]],\n","\n","       [[0, 0, 0, ..., 0, 0, 0],\n","        [0, 0, 0, ..., 0, 0, 0],\n","        [0, 0, 0, ..., 0, 0, 0],\n","        ...,\n","        [0, 0, 0, ..., 0, 0, 0],\n","        [0, 0, 0, ..., 0, 0, 0],\n","        [0, 0, 0, ..., 0, 0, 0]]], dtype=uint8)"]},"execution_count":2,"metadata":{},"output_type":"execute_result"}],"source":["# Load MNIST dataset directly from tensorflow\n","from tensorflow.keras.datasets.mnist import load_data\n","# Data is returned already split into train and test data, and inputs and outputs\n","(train_x, train_y), (test_x, test_y) = load_data()\n","# Show the contents of the training inputs\n","train_x"]},{"cell_type":"code","execution_count":3,"id":"897c8f48","metadata":{"execution":{"iopub.execute_input":"2023-11-02T21:23:43.430717Z","iopub.status.busy":"2023-11-02T21:23:43.430134Z","iopub.status.idle":"2023-11-02T21:23:43.551547Z","shell.execute_reply":"2023-11-02T21:23:43.550389Z"},"papermill":{"duration":0.128157,"end_time":"2023-11-02T21:23:43.554332","exception":false,"start_time":"2023-11-02T21:23:43.426175","status":"completed"},"tags":[]},"outputs":[{"data":{"text/plain":["array([[[0.        , 0.        , 0.        , 0.        , 0.        ,\n","         0.        , 0.        , 0.        , 0.        , 0.        ,\n","         0.        , 0.        , 0.        , 0.        , 0.        ,\n","         0.        , 0.        , 0.        , 0.        , 0.        ,\n","         0.        , 0.        , 0.        , 0.        , 0.        ,\n","         0.        , 0.        , 0.        ],\n","        [0.        , 0.        , 0.        , 0.        , 0.        ,\n","         0.        , 0.        , 0.        , 0.        , 0.        ,\n","         0.        , 0.        , 0.        , 0.        , 0.        ,\n","         0.        , 0.        , 0.        , 0.        , 0.        ,\n","         0.        , 0.        , 0.        , 0.        , 0.        ,\n","         0.        , 0.        , 0.        ],\n","        [0.        , 0.        , 0.        , 0.        , 0.        ,\n","         0.        , 0.        , 0.        , 0.        , 0.        ,\n","         0.        , 0.        , 0.        , 0.        , 0.        ,\n","         0.        , 0.        , 0.        , 0.        , 0.        ,\n","         0.        , 0.        , 0.        , 0.        , 0.        ,\n","         0.        , 0.        , 0.        ],\n","        [0.        , 0.        , 0.        , 0.        , 0.        ,\n","         0.        , 0.        , 0.        , 0.        , 0.        ,\n","         0.        , 0.        , 0.        , 0.        , 0.        ,\n","         0.        , 0.        , 0.        , 0.        , 0.        ,\n","         0.        , 0.        , 0.        , 0.        , 0.        ,\n","         0.        , 0.        , 0.        ],\n","        [0.        , 0.        , 0.        , 0.        , 0.        ,\n","         0.        , 0.        , 0.        , 0.        , 0.        ,\n","         0.        , 0.        , 0.        , 0.        , 0.        ,\n","         0.        , 0.        , 0.        , 0.        , 0.        ,\n","         0.        , 0.        , 0.        , 0.        , 0.        ,\n","         0.        , 0.        , 0.        ],\n","        [0.        , 0.        , 0.        , 0.        , 0.        ,\n","         0.        , 0.        , 0.        , 0.        , 0.        ,\n","         0.        , 0.        , 0.01176471, 0.07058824, 0.07058824,\n","         0.07058824, 0.49411765, 0.53333333, 0.68627451, 0.10196078,\n","         0.65098039, 1.        , 0.96862745, 0.49803922, 0.        ,\n","         0.        , 0.        , 0.        ],\n","        [0.        , 0.        , 0.        , 0.        , 0.        ,\n","         0.        , 0.        , 0.        , 0.11764706, 0.14117647,\n","         0.36862745, 0.60392157, 0.66666667, 0.99215686, 0.99215686,\n","         0.99215686, 0.99215686, 0.99215686, 0.88235294, 0.6745098 ,\n","         0.99215686, 0.94901961, 0.76470588, 0.25098039, 0.        ,\n","         0.        , 0.        , 0.        ],\n","        [0.        , 0.        , 0.        , 0.        , 0.        ,\n","         0.        , 0.        , 0.19215686, 0.93333333, 0.99215686,\n","         0.99215686, 0.99215686, 0.99215686, 0.99215686, 0.99215686,\n","         0.99215686, 0.99215686, 0.98431373, 0.36470588, 0.32156863,\n","         0.32156863, 0.21960784, 0.15294118, 0.        , 0.        ,\n","         0.        , 0.        , 0.        ],\n","        [0.        , 0.        , 0.        , 0.        , 0.        ,\n","         0.        , 0.        , 0.07058824, 0.85882353, 0.99215686,\n","         0.99215686, 0.99215686, 0.99215686, 0.99215686, 0.77647059,\n","         0.71372549, 0.96862745, 0.94509804, 0.        , 0.        ,\n","         0.        , 0.        , 0.        , 0.        , 0.        ,\n","         0.        , 0.        , 0.        ],\n","        [0.        , 0.        , 0.        , 0.        , 0.        ,\n","         0.        , 0.        , 0.        , 0.31372549, 0.61176471,\n","         0.41960784, 0.99215686, 0.99215686, 0.80392157, 0.04313725,\n","         0.        , 0.16862745, 0.60392157, 0.        , 0.        ,\n","         0.        , 0.        , 0.        , 0.        , 0.        ,\n","         0.        , 0.        , 0.        ],\n","        [0.        , 0.        , 0.        , 0.        , 0.        ,\n","         0.        , 0.        , 0.        , 0.        , 0.05490196,\n","         0.00392157, 0.60392157, 0.99215686, 0.35294118, 0.        ,\n","         0.        , 0.        , 0.        , 0.        , 0.        ,\n","         0.        , 0.        , 0.        , 0.        , 0.        ,\n","         0.        , 0.        , 0.        ],\n","        [0.        , 0.        , 0.        , 0.        , 0.        ,\n","         0.        , 0.        , 0.        , 0.        , 0.        ,\n","         0.        , 0.54509804, 0.99215686, 0.74509804, 0.00784314,\n","         0.        , 0.        , 0.        , 0.        , 0.        ,\n","         0.        , 0.        , 0.        , 0.        , 0.        ,\n","         0.        , 0.        , 0.        ],\n","        [0.        , 0.        , 0.        , 0.        , 0.        ,\n","         0.        , 0.        , 0.        , 0.        , 0.        ,\n","         0.        , 0.04313725, 0.74509804, 0.99215686, 0.2745098 ,\n","         0.        , 0.        , 0.        , 0.        , 0.        ,\n","         0.        , 0.        , 0.        , 0.        , 0.        ,\n","         0.        , 0.        , 0.        ],\n","        [0.        , 0.        , 0.        , 0.        , 0.        ,\n","         0.        , 0.        , 0.        , 0.        , 0.        ,\n","         0.        , 0.        , 0.1372549 , 0.94509804, 0.88235294,\n","         0.62745098, 0.42352941, 0.00392157, 0.        , 0.        ,\n","         0.        , 0.        , 0.        , 0.        , 0.        ,\n","         0.        , 0.        , 0.        ],\n","        [0.        , 0.        , 0.        , 0.        , 0.        ,\n","         0.        , 0.        , 0.        , 0.        , 0.        ,\n","         0.        , 0.        , 0.        , 0.31764706, 0.94117647,\n","         0.99215686, 0.99215686, 0.46666667, 0.09803922, 0.        ,\n","         0.        , 0.        , 0.        , 0.        , 0.        ,\n","         0.        , 0.        , 0.        ],\n","        [0.        , 0.        , 0.        , 0.        , 0.        ,\n","         0.        , 0.        , 0.        , 0.        , 0.        ,\n","         0.        , 0.        , 0.        , 0.        , 0.17647059,\n","         0.72941176, 0.99215686, 0.99215686, 0.58823529, 0.10588235,\n","         0.        , 0.        , 0.        , 0.        , 0.        ,\n","         0.        , 0.        , 0.        ],\n","        [0.        , 0.        , 0.        , 0.        , 0.        ,\n","         0.        , 0.        , 0.        , 0.        , 0.        ,\n","         0.        , 0.        , 0.        , 0.        , 0.        ,\n","         0.0627451 , 0.36470588, 0.98823529, 0.99215686, 0.73333333,\n","         0.        , 0.        , 0.        , 0.        , 0.        ,\n","         0.        , 0.        , 0.        ],\n","        [0.        , 0.        , 0.        , 0.        , 0.        ,\n","         0.        , 0.        , 0.        , 0.        , 0.        ,\n","         0.        , 0.        , 0.        , 0.        , 0.        ,\n","         0.        , 0.        , 0.97647059, 0.99215686, 0.97647059,\n","         0.25098039, 0.        , 0.        , 0.        , 0.        ,\n","         0.        , 0.        , 0.        ],\n","        [0.        , 0.        , 0.        , 0.        , 0.        ,\n","         0.        , 0.        , 0.        , 0.        , 0.        ,\n","         0.        , 0.        , 0.        , 0.        , 0.18039216,\n","         0.50980392, 0.71764706, 0.99215686, 0.99215686, 0.81176471,\n","         0.00784314, 0.        , 0.        , 0.        , 0.        ,\n","         0.        , 0.        , 0.        ],\n","        [0.        , 0.        , 0.        , 0.        , 0.        ,\n","         0.        , 0.        , 0.        , 0.        , 0.        ,\n","         0.        , 0.        , 0.15294118, 0.58039216, 0.89803922,\n","         0.99215686, 0.99215686, 0.99215686, 0.98039216, 0.71372549,\n","         0.        , 0.        , 0.        , 0.        , 0.        ,\n","         0.        , 0.        , 0.        ],\n","        [0.        , 0.        , 0.        , 0.        , 0.        ,\n","         0.        , 0.        , 0.        , 0.        , 0.        ,\n","         0.09411765, 0.44705882, 0.86666667, 0.99215686, 0.99215686,\n","         0.99215686, 0.99215686, 0.78823529, 0.30588235, 0.        ,\n","         0.        , 0.        , 0.        , 0.        , 0.        ,\n","         0.        , 0.        , 0.        ],\n","        [0.        , 0.        , 0.        , 0.        , 0.        ,\n","         0.        , 0.        , 0.        , 0.09019608, 0.25882353,\n","         0.83529412, 0.99215686, 0.99215686, 0.99215686, 0.99215686,\n","         0.77647059, 0.31764706, 0.00784314, 0.        , 0.        ,\n","         0.        , 0.        , 0.        , 0.        , 0.        ,\n","         0.        , 0.        , 0.        ],\n","        [0.        , 0.        , 0.        , 0.        , 0.        ,\n","         0.        , 0.07058824, 0.67058824, 0.85882353, 0.99215686,\n","         0.99215686, 0.99215686, 0.99215686, 0.76470588, 0.31372549,\n","         0.03529412, 0.        , 0.        , 0.        , 0.        ,\n","         0.        , 0.        , 0.        , 0.        , 0.        ,\n","         0.        , 0.        , 0.        ],\n","        [0.        , 0.        , 0.        , 0.        , 0.21568627,\n","         0.6745098 , 0.88627451, 0.99215686, 0.99215686, 0.99215686,\n","         0.99215686, 0.95686275, 0.52156863, 0.04313725, 0.        ,\n","         0.        , 0.        , 0.        , 0.        , 0.        ,\n","         0.        , 0.        , 0.        , 0.        , 0.        ,\n","         0.        , 0.        , 0.        ],\n","        [0.        , 0.        , 0.        , 0.        , 0.53333333,\n","         0.99215686, 0.99215686, 0.99215686, 0.83137255, 0.52941176,\n","         0.51764706, 0.0627451 , 0.        , 0.        , 0.        ,\n","         0.        , 0.        , 0.        , 0.        , 0.        ,\n","         0.        , 0.        , 0.        , 0.        , 0.        ,\n","         0.        , 0.        , 0.        ],\n","        [0.        , 0.        , 0.        , 0.        , 0.        ,\n","         0.        , 0.        , 0.        , 0.        , 0.        ,\n","         0.        , 0.        , 0.        , 0.        , 0.        ,\n","         0.        , 0.        , 0.        , 0.        , 0.        ,\n","         0.        , 0.        , 0.        , 0.        , 0.        ,\n","         0.        , 0.        , 0.        ],\n","        [0.        , 0.        , 0.        , 0.        , 0.        ,\n","         0.        , 0.        , 0.        , 0.        , 0.        ,\n","         0.        , 0.        , 0.        , 0.        , 0.        ,\n","         0.        , 0.        , 0.        , 0.        , 0.        ,\n","         0.        , 0.        , 0.        , 0.        , 0.        ,\n","         0.        , 0.        , 0.        ],\n","        [0.        , 0.        , 0.        , 0.        , 0.        ,\n","         0.        , 0.        , 0.        , 0.        , 0.        ,\n","         0.        , 0.        , 0.        , 0.        , 0.        ,\n","         0.        , 0.        , 0.        , 0.        , 0.        ,\n","         0.        , 0.        , 0.        , 0.        , 0.        ,\n","         0.        , 0.        , 0.        ]]])"]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["# Normalize the input values \n","train_x = train_x / 255.0\n","test_x = test_x / 255.0\n","\n","import matplotlib.pyplot as plt\n","\n","# Show the normalized trainining inputs\n","train_x[:1]"]},{"cell_type":"code","execution_count":4,"id":"7cc6b935","metadata":{"execution":{"iopub.execute_input":"2023-11-02T21:23:43.562258Z","iopub.status.busy":"2023-11-02T21:23:43.561936Z","iopub.status.idle":"2023-11-02T21:24:04.945544Z","shell.execute_reply":"2023-11-02T21:24:04.944436Z"},"papermill":{"duration":21.389993,"end_time":"2023-11-02T21:24:04.947708","exception":false,"start_time":"2023-11-02T21:23:43.557715","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/5\n","1875/1875 [==============================] - 4s 2ms/step - loss: 0.4237 - accuracy: 0.8865\n","Epoch 2/5\n","1875/1875 [==============================] - 4s 2ms/step - loss: 0.2160 - accuracy: 0.9385\n","Epoch 3/5\n","1875/1875 [==============================] - 4s 2ms/step - loss: 0.1628 - accuracy: 0.9521\n","Epoch 4/5\n","1875/1875 [==============================] - 4s 2ms/step - loss: 0.1295 - accuracy: 0.9621\n","Epoch 5/5\n","1875/1875 [==============================] - 4s 2ms/step - loss: 0.1079 - accuracy: 0.9681\n"]},{"data":{"text/plain":["<keras.callbacks.History at 0x7a217a115350>"]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense, Flatten, Dropout\n","from tensorflow.keras.losses import SparseCategoricalCrossentropy\n","\n","# Create our model. A sequential model is a sequence of layers. \n","model = Sequential()\n","# Flatten the input tensors\n","model.add(Flatten(input_shape=(28,28)))\n","# Fully-connected layer with 120 neurons\n","model.add(Dense(120, activation='sigmoid'))\n","# Dropout layer with 0.1 drop out ratio i.e. 10% of the inputs will randomly be set to 0\n","# Can reduce overfitting (increase regularization)\n","model.add(Dropout(0.1))\n","# Output layer with one neuron per class\n","model.add(Dense(10))\n","\n","# Finish our model by specifying optimizer, loss function and metrics \n","model.compile(optimizer='adam', loss=SparseCategoricalCrossentropy(from_logits=True), metrics=['accuracy'])\n","\n","# Train our network using 32 images between each weight update and run through all the data 5 times\n","model.fit(train_x, train_y, epochs=5, batch_size=32)"]},{"cell_type":"code","execution_count":5,"id":"e57191ec","metadata":{"execution":{"iopub.execute_input":"2023-11-02T21:24:04.998014Z","iopub.status.busy":"2023-11-02T21:24:04.997417Z","iopub.status.idle":"2023-11-02T21:24:05.672243Z","shell.execute_reply":"2023-11-02T21:24:05.671203Z"},"papermill":{"duration":0.702334,"end_time":"2023-11-02T21:24:05.674219","exception":false,"start_time":"2023-11-02T21:24:04.971885","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["313/313 [==============================] - 1s 1ms/step - loss: 0.0999 - accuracy: 0.9697\n"]},{"data":{"text/plain":["[0.09985240548849106, 0.9696999788284302]"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["# Evaluate the performance on test data\n","model.evaluate(test_x, test_y)"]},{"cell_type":"code","execution_count":6,"id":"ff8d5d7d","metadata":{"execution":{"iopub.execute_input":"2023-11-02T21:24:05.72711Z","iopub.status.busy":"2023-11-02T21:24:05.726743Z","iopub.status.idle":"2023-11-02T21:25:47.284845Z","shell.execute_reply":"2023-11-02T21:25:47.283647Z"},"papermill":{"duration":101.588352,"end_time":"2023-11-02T21:25:47.28751","exception":false,"start_time":"2023-11-02T21:24:05.699158","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/5\n","625/625 [==============================] - 2s 3ms/step - loss: 0.3729 - accuracy: 0.8945\n","Epoch 2/5\n","625/625 [==============================] - 2s 2ms/step - loss: 0.1844 - accuracy: 0.9464\n","Epoch 3/5\n","625/625 [==============================] - 1s 2ms/step - loss: 0.1364 - accuracy: 0.9606\n","Epoch 4/5\n","625/625 [==============================] - 2s 2ms/step - loss: 0.1086 - accuracy: 0.9681\n","Epoch 5/5\n","625/625 [==============================] - 1s 2ms/step - loss: 0.0887 - accuracy: 0.9729\n","313/313 [==============================] - 1s 1ms/step - loss: 0.0990 - accuracy: 0.9707\n","Epoch 1/5\n","625/625 [==============================] - 2s 2ms/step - loss: 0.3698 - accuracy: 0.8956\n","Epoch 2/5\n","625/625 [==============================] - 2s 2ms/step - loss: 0.1786 - accuracy: 0.9481\n","Epoch 3/5\n","625/625 [==============================] - 1s 2ms/step - loss: 0.1301 - accuracy: 0.9628\n","Epoch 4/5\n","625/625 [==============================] - 2s 2ms/step - loss: 0.1021 - accuracy: 0.9701\n","Epoch 5/5\n","625/625 [==============================] - 2s 2ms/step - loss: 0.0831 - accuracy: 0.9751\n","313/313 [==============================] - 1s 1ms/step - loss: 0.1089 - accuracy: 0.9683\n","Epoch 1/5\n","625/625 [==============================] - 2s 3ms/step - loss: 0.3705 - accuracy: 0.8955\n","Epoch 2/5\n","625/625 [==============================] - 2s 3ms/step - loss: 0.1752 - accuracy: 0.9489\n","Epoch 3/5\n","625/625 [==============================] - 2s 3ms/step - loss: 0.1272 - accuracy: 0.9632\n","Epoch 4/5\n","625/625 [==============================] - 2s 3ms/step - loss: 0.1001 - accuracy: 0.9711\n","Epoch 5/5\n","625/625 [==============================] - 2s 3ms/step - loss: 0.0801 - accuracy: 0.9769\n","313/313 [==============================] - 1s 2ms/step - loss: 0.1064 - accuracy: 0.9678\n","Epoch 1/5\n","625/625 [==============================] - 2s 3ms/step - loss: 0.4056 - accuracy: 0.8835\n","Epoch 2/5\n","625/625 [==============================] - 2s 3ms/step - loss: 0.1982 - accuracy: 0.9417\n","Epoch 3/5\n","625/625 [==============================] - 2s 3ms/step - loss: 0.1491 - accuracy: 0.9564\n","Epoch 4/5\n","625/625 [==============================] - 2s 3ms/step - loss: 0.1197 - accuracy: 0.9645\n","Epoch 5/5\n","625/625 [==============================] - 2s 3ms/step - loss: 0.0996 - accuracy: 0.9698\n","313/313 [==============================] - 1s 2ms/step - loss: 0.1037 - accuracy: 0.9684\n","Epoch 1/5\n","625/625 [==============================] - 2s 3ms/step - loss: 0.3911 - accuracy: 0.8883\n","Epoch 2/5\n","625/625 [==============================] - 2s 3ms/step - loss: 0.1874 - accuracy: 0.9457\n","Epoch 3/5\n","625/625 [==============================] - 2s 3ms/step - loss: 0.1397 - accuracy: 0.9587\n","Epoch 4/5\n","625/625 [==============================] - 2s 3ms/step - loss: 0.1119 - accuracy: 0.9666\n","Epoch 5/5\n","625/625 [==============================] - 2s 3ms/step - loss: 0.0953 - accuracy: 0.9709\n","313/313 [==============================] - 1s 2ms/step - loss: 0.1048 - accuracy: 0.9683\n","Epoch 1/5\n","625/625 [==============================] - 2s 3ms/step - loss: 0.3995 - accuracy: 0.8853\n","Epoch 2/5\n","625/625 [==============================] - 2s 3ms/step - loss: 0.1922 - accuracy: 0.9437\n","Epoch 3/5\n","625/625 [==============================] - 2s 3ms/step - loss: 0.1445 - accuracy: 0.9571\n","Epoch 4/5\n","625/625 [==============================] - 2s 3ms/step - loss: 0.1152 - accuracy: 0.9658\n","Epoch 5/5\n","625/625 [==============================] - 2s 3ms/step - loss: 0.0979 - accuracy: 0.9706\n","313/313 [==============================] - 1s 2ms/step - loss: 0.1046 - accuracy: 0.9685\n","Epoch 1/5\n","625/625 [==============================] - 2s 3ms/step - loss: 0.4297 - accuracy: 0.8734\n","Epoch 2/5\n","625/625 [==============================] - 2s 3ms/step - loss: 0.2160 - accuracy: 0.9363\n","Epoch 3/5\n","625/625 [==============================] - 2s 3ms/step - loss: 0.1635 - accuracy: 0.9519\n","Epoch 4/5\n","625/625 [==============================] - 2s 3ms/step - loss: 0.1347 - accuracy: 0.9596\n","Epoch 5/5\n","625/625 [==============================] - 2s 3ms/step - loss: 0.1180 - accuracy: 0.9649\n","313/313 [==============================] - 1s 2ms/step - loss: 0.1089 - accuracy: 0.9668\n","Epoch 1/5\n","625/625 [==============================] - 2s 3ms/step - loss: 0.4249 - accuracy: 0.8757\n","Epoch 2/5\n","625/625 [==============================] - 2s 3ms/step - loss: 0.2120 - accuracy: 0.9369\n","Epoch 3/5\n","625/625 [==============================] - 2s 3ms/step - loss: 0.1642 - accuracy: 0.9517\n","Epoch 4/5\n","625/625 [==============================] - 2s 3ms/step - loss: 0.1346 - accuracy: 0.9585\n","Epoch 5/5\n","625/625 [==============================] - 2s 3ms/step - loss: 0.1148 - accuracy: 0.9658\n","313/313 [==============================] - 1s 2ms/step - loss: 0.1172 - accuracy: 0.9646\n","Epoch 1/5\n","625/625 [==============================] - 2s 3ms/step - loss: 0.4382 - accuracy: 0.8730\n","Epoch 2/5\n","625/625 [==============================] - 2s 3ms/step - loss: 0.2168 - accuracy: 0.9369\n","Epoch 3/5\n","625/625 [==============================] - 2s 3ms/step - loss: 0.1653 - accuracy: 0.9512\n","Epoch 4/5\n","625/625 [==============================] - 2s 3ms/step - loss: 0.1354 - accuracy: 0.9594\n","Epoch 5/5\n","625/625 [==============================] - 2s 3ms/step - loss: 0.1134 - accuracy: 0.9659\n","313/313 [==============================] - 1s 1ms/step - loss: 0.1108 - accuracy: 0.9671\n","Epoch 1/5\n","938/938 [==============================] - 3s 3ms/step - loss: 0.3175 - accuracy: 0.9100\n","Epoch 2/5\n","938/938 [==============================] - 3s 3ms/step - loss: 0.1464 - accuracy: 0.9572\n","Epoch 3/5\n","938/938 [==============================] - 2s 3ms/step - loss: 0.1089 - accuracy: 0.9681\n","Epoch 4/5\n","938/938 [==============================] - 3s 3ms/step - loss: 0.0866 - accuracy: 0.9736\n","Epoch 5/5\n","938/938 [==============================] - 3s 3ms/step - loss: 0.0718 - accuracy: 0.9785\n"]},{"data":{"text/plain":["GridSearchCV(cv=3,\n","             estimator=<keras.wrappers.scikit_learn.KerasClassifier object at 0x7a215c66a450>,\n","             param_grid={'drop_out': [0.1, 0.2, 0.3]})"]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["from sklearn.model_selection import GridSearchCV\n","from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n","\n","# A function for creating our model. The arguments are parameters the we want to be controllable\n","def create_model(drop_out):\n","    # The same architecture as before, but now the drop_out is controllable by the search\n","    model = Sequential([\n","          Flatten(input_shape=(28, 28)),\n","          Dense(128, activation='relu'),\n","          Dropout(drop_out),\n","          Dense(10)\n","    ])\n","    # Finish the model by specifying optimizer, loss, and metric\n","    model.compile(optimizer='adam', loss=SparseCategoricalCrossentropy(from_logits=True), metrics=['accuracy'])\n","    return model\n","\n","# Create our classifier that points to the function above\n","classifier = KerasClassifier(create_model, epochs=5, batch_size=64)\n","\n","# Set up grid search like normal\n","params = {'drop_out':[0.1, 0.2, 0.3]}\n","grid = GridSearchCV(classifier, params,cv=3)\n","grid.fit(train_x, train_y)"]},{"cell_type":"code","execution_count":7,"id":"4d861e08","metadata":{"execution":{"iopub.execute_input":"2023-11-02T21:25:47.544134Z","iopub.status.busy":"2023-11-02T21:25:47.542792Z","iopub.status.idle":"2023-11-02T21:26:22.604745Z","shell.execute_reply":"2023-11-02T21:26:22.603693Z"},"papermill":{"duration":35.194093,"end_time":"2023-11-02T21:26:22.607452","exception":false,"start_time":"2023-11-02T21:25:47.413359","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["Trial 2 Complete [00h 00m 13s]\n","val_loss: 0.19156064093112946\n","\n","Best val_loss So Far: 0.19156064093112946\n","Total elapsed time: 00h 00m 34s\n"]},{"data":{"text/plain":["<keras.engine.sequential.Sequential at 0x7a21326ade50>"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["import keras_tuner\n","\n","# A function for creating our model. \n","def create_model1(hp):\n","    # The same architecture as before, but now the drop_out is controllable by the search\n","    model = Sequential([\n","          Flatten(input_shape=(28, 28)),\n","          Dense(128, activation='relu'),\n","          Dropout(hp.Float('drop_out', min_value=0.1, max_value=0.3, step=0.1)),\n","          Dense(10)\n","    ])\n","    # Finish the model by specifying optimizer, loss, and metric\n","    model.compile(optimizer='adam', loss=SparseCategoricalCrossentropy(from_logits=True), metrics=['accuracy'])\n","    return model\n","\n","tuner = keras_tuner.RandomSearch(create_model1,objective='val_loss',max_trials=5,overwrite=True)\n","tuner.search(train_x[:10000],train_y[:10000],validation_data=(train_x[10000:],train_y[10000:]),epochs=5,batch_size=32)\n","best = tuner.get_best_models()[0]\n","best"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.12"},"papermill":{"default_parameters":{},"duration":177.55963,"end_time":"2023-11-02T21:26:26.246911","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2023-11-02T21:23:28.687281","version":"2.3.4"}},"nbformat":4,"nbformat_minor":5}